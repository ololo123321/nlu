# relation-extraction
TODO:
* [x] если loss_coef по какому-то таску ровно ноль, то не учитывать скор по этому таску в усреднённом скоре
* [ ] написать скрипты по обучению и инференсу на разных датасетах
* [ ] положить некоторые ноутбуки под гит
* [x] инференс на спанах с перекрытиями
* [ ] базовые тесты моделей (с замоканными экстракторами)
* [ ] оценка качества end2end
* [ ] train, validation, test в докерах
* [ ] тесты функций из src.model.utils
* [x] качество мерить на уровне документов, а не кусочков.  
Пусть:
* w - размер кусочка (в предложениях);
* r(a, b) - отношение между сущностями a и b;
* i - индекс предложения сущности a;
* j - индекс предложения сущности b.  
Тогда в кусочках не будет таких r, что abs(i - j) >= w.  

* [ ] постпроцессинг предиктов модели BertForCoreferenceResolutionV2:
* петли (head != dep);
* циклы (удалять стрелки "->" в случае циклов);
* несколько исходящих рёбер (использовать логиты);
* несколько входящих рёбер (хз). 
* [ ] получения компонент связности
* [ ] метрики для coreference resolution (чистый код сохранения в conll -> вызов скорера из питона через subprocess)

Идеи для улучшения модели разрешения кореференций:
* [ ] увеличить ширину окна 
* [ ] увеличить куски до максимально возможного размера (512 bpe-pieces). тогда скорей всего придётся учить с аккумуляцией градиентов (в случае берта).
* [ ] более умная кластеризация. например, если есть большая компонента связности, 
которую никак не ухватить моделью, и модель её разбила на k компонент, 
то можно их попробовать объединить по группам существительного. 
Например, интуитивно понятно, что компоненты {"Иван Иванов", "он"}, {"Ивану"} можно объединить в одну: {"Иван Иванов", "он", "Ивану"}.